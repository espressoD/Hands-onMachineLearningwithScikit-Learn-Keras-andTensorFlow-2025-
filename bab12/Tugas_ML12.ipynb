{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ““ Notebook - Teori & Praktik Bab 12: Model Kustom & Pelatihan dengan TensorFlow\n",
    "\n",
    "Bab ini berfokus pada fleksibilitas TensorFlow. Meskipun API Keras standar sudah mencakup sebagian besar kebutuhan, terkadang diperlukan kendali lebih dalam untuk kasus khusus, seperti loss function yang unik, struktur layer yang tidak biasa, atau loop pelatihan manual.\n",
    "\n",
    "Topik pembahasan meliputi:\n",
    "1.  **Tensor & Operasi**: Struktur data dasar TensorFlow.\n",
    "2.  **Custom Loss Function**: Membuat fungsi kerugian sendiri.\n",
    "3.  **Custom Metrics**: Membuat metrik evaluasi sendiri (Stateful Metrics).\n",
    "4.  **Custom Layers**: Membuat layer jaringan saraf sendiri.\n",
    "5.  **Custom Models**: Membuat arsitektur model sendiri.\n",
    "6.  **Custom Training Loop**: Melatih model secara manual menggunakan `GradientTape`.\n",
    "7.  **TensorFlow Functions**: Optimasi performa graf dengan `@tf.function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor dan Operasi Dasar\n",
    "\n",
    "### Teori\n",
    "Tensor adalah struktur data utama dalam TensorFlow, mirip dengan array NumPy, tetapi memiliki kemampuan untuk diproses oleh GPU/TPU dan merupakan bagian dari graf komputasi. Tensor bersifat *immutable* (tidak dapat diubah setelah dibuat), kecuali `tf.Variable` yang digunakan untuk menyimpan bobot model.\n",
    "\n",
    "Operasi matematika pada tensor dilakukan menggunakan fungsi-fungsi `tf.*` (misalnya `tf.add`, `tf.square`, `tf.matmul`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor t:\n",
      " tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "Ukuran (Shape): (2, 3)\n",
      "Tipe Data: <dtype: 'float32'>\n",
      "\n",
      "Penjumlahan (t + 10):\n",
      " tf.Tensor(\n",
      "[[11. 12. 13.]\n",
      " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
      "Kuadrat (tf.square(t)):\n",
      " tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n",
      "Perkalian Matriks (t @ t.T):\n",
      " tf.Tensor(\n",
      "[[14. 32.]\n",
      " [32. 77.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "NumPy ke Tensor: tf.Tensor([2. 4. 5.], shape=(3,), dtype=float64)\n",
      "Tensor ke NumPy: [2. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Pembuatan Tensor Konstan\n",
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "\n",
    "# Operasi Dasar\n",
    "print(\"Tensor t:\\n\", t)\n",
    "print(\"Ukuran (Shape):\", t.shape)\n",
    "print(\"Tipe Data:\", t.dtype)\n",
    "\n",
    "# Operasi Matematika\n",
    "print(\"\\nPenjumlahan (t + 10):\\n\", t + 10)\n",
    "print(\"Kuadrat (tf.square(t)):\\n\", tf.square(t))\n",
    "print(\"Perkalian Matriks (t @ t.T):\\n\", t @ tf.transpose(t))\n",
    "\n",
    "# Konversi NumPy ke Tensor dan sebaliknya\n",
    "a = np.array([2., 4., 5.])\n",
    "tf_a = tf.constant(a)\n",
    "print(\"\\nNumPy ke Tensor:\", tf_a)\n",
    "print(\"Tensor ke NumPy:\", tf_a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Loss Function\n",
    "\n",
    "### Teori\n",
    "Ketika fungsi *loss* bawaan (seperti MSE atau CrossEntropy) tidak sesuai dengan masalah yang dihadapi, fungsi kustom dapat dibuat. \n",
    "\n",
    "Fungsi *loss* kustom harus menerima dua argumen: `y_true` (label asli) dan `y_pred` (prediksi model), serta mengembalikan nilai error per instans data. Contoh di bawah mengimplementasikan **Huber Loss**, yang lebih tahan terhadap *outlier* dibandingkan Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huber Loss (Error Besar): [1.]\n"
     ]
    }
   ],
   "source": [
    "def custom_huber_loss(y_true, y_pred):\n",
    "    threshold = 1.0\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < threshold\n",
    "    \n",
    "    # Jika error kecil: kuadratkan (seperti MSE)\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    # Jika error besar: linear (seperti MAE)\n",
    "    linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "    \n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "# Pengujian Fungsi Loss\n",
    "y_true = tf.constant([1.0])\n",
    "y_pred = tf.constant([2.5]) # Error = 1.5 (Besar)\n",
    "print(\"Huber Loss (Error Besar):\", custom_huber_loss(y_true, y_pred).numpy())\n",
    "\n",
    "# Penggunaan dalam Model Keras\n",
    "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[1])])\n",
    "model.compile(loss=custom_huber_loss, optimizer=\"sgd\")\n",
    "# model.fit(...) # Dapat digunakan langsung saat training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Metrics (Stateful)\n",
    "\n",
    "### Teori\n",
    "Berbeda dengan *Loss* yang dihitung per *batch*, Metrik (seperti Akurasi atau Precision) seringkali perlu diakumulasikan di seluruh dataset (Stateful). \n",
    "\n",
    "Untuk membuat metrik kustom yang *stateful*, kelas `keras.metrics.Metric` harus di-*subclass*. Metode `update_state` digunakan untuk memperbarui akumulasi, dan `result` untuk menghitung hasil akhir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Akumulasi Metrik: 1.0\n"
     ]
    }
   ],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = custom_huber_loss\n",
    "        \n",
    "        # PERBAIKAN: Gunakan keyword argument 'name', 'shape', dan 'initializer' secara eksplisit\n",
    "        self.total = self.add_weight(name=\"total\", shape=(), initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\", shape=(), initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.total.assign(0.)\n",
    "        self.count.assign(0.)\n",
    "\n",
    "# Pengujian Metrik\n",
    "m = HuberMetric()\n",
    "m.update_state(tf.constant([1.0]), tf.constant([2.5]))\n",
    "print(\"Hasil Akumulasi Metrik:\", m.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Layers\n",
    "\n",
    "### Teori\n",
    "Jika layer standar (Dense, Conv2D, Dropout) tidak cukup, layer kustom dapat dibuat dengan menurunkan kelas `keras.layers.Layer`.\n",
    "\n",
    "Metode penting:\n",
    "* `__init__`: Menerima hyperparameter.\n",
    "* `build(input_shape)`: Membuat bobot (weights) saat bentuk input diketahui.\n",
    "* `call(inputs)`: Melakukan operasi perhitungan (forward pass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Output dari model dengan Custom Layer:\n",
      "tf.Tensor(\n",
      "[[0.1977665]\n",
      " [0.5968505]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        # Membuat kernel (weights) dan bias\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        # Operasi matriks: X * W + b\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "# Menggunakan Layer Kustom\n",
    "model_custom = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(5,)), # Input shape explicit\n",
    "    MyDense(10, activation=\"relu\"),\n",
    "    MyDense(1)\n",
    "])\n",
    "\n",
    "print(\"Output dari model dengan Custom Layer:\")\n",
    "print(model_custom(tf.random.uniform((2, 5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Models\n",
    "\n",
    "### Teori\n",
    "Untuk arsitektur yang kompleks (misalnya yang memiliki skip connection atau input ganda yang dinamis), kelas `keras.Model` dapat di-*subclass*.\n",
    "\n",
    "Layer didefinisikan di `__init__`, dan alur data didefinisikan di `call`. Ini memberikan fleksibilitas penuh seperti pemrograman Python biasa (bisa menggunakan `if`, `for`, dll dalam `call`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ residual_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ residual_block (\u001b[38;5;33mResidualBlock\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m220\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m11\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> (924.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m231\u001b[0m (924.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> (924.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m231\u001b[0m (924.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Membuat list hidden layers\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z # Skip connection (menambahkan input asli ke output)\n",
    "\n",
    "# Menggunakan Custom Block dalam Model\n",
    "model_res = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10,)),\n",
    "    ResidualBlock(n_layers=2, n_neurons=10),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Training Loops (GradientTape)\n",
    "\n",
    "### Teori\n",
    "Metode `.fit()` sangat kuat, tetapi terkadang peneliti membutuhkan kendali penuh atas setiap langkah pelatihan (misalnya untuk GANs atau Reinforcement Learning).\n",
    "\n",
    "Ini dilakukan dengan **GradientTape**:\n",
    "1.  Buka blok `with tf.GradientTape() as tape:`.\n",
    "2.  Lakukan *forward pass* (prediksi).\n",
    "3.  Hitung *loss*.\n",
    "4.  Minta tape untuk menghitung gradien loss terhadap variabel model.\n",
    "5.  Gunakan optimizer untuk mengupdate variabel berdasarkan gradien tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loop Manual dimulai...\n",
      "Epoch 1, Loss: 17.1847\n",
      "Epoch 2, Loss: 14.3423\n",
      "Epoch 3, Loss: 11.9761\n",
      "Epoch 4, Loss: 10.0063\n",
      "Epoch 5, Loss: 8.3664\n",
      "Weights & Bias hasil training: [array([[0.46739513]], dtype=float32), array([0.7787275], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Data Dummy Linear Regression\n",
    "X_train = tf.random.normal(shape=(100, 1))\n",
    "y_train = 3 * X_train + 2 + tf.random.normal(shape=(100, 1)) * 0.5\n",
    "\n",
    "# Model Sederhana\n",
    "model_manual = keras.layers.Dense(1, input_shape=[1])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.05)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "print(\"Training Loop Manual dimulai...\")\n",
    "for epoch in range(5):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1. Forward pass\n",
    "        y_pred = model_manual(X_train)\n",
    "        # 2. Hitung Loss\n",
    "        loss = loss_fn(y_train, y_pred)\n",
    "    \n",
    "    # 3. Hitung Gradien\n",
    "    gradients = tape.gradient(loss, model_manual.trainable_variables)\n",
    "    \n",
    "    # 4. Update Weights\n",
    "    optimizer.apply_gradients(zip(gradients, model_manual.trainable_variables))\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.numpy():.4f}\")\n",
    "\n",
    "# Hasil weights harus mendekati 3 dan bias mendekati 2\n",
    "print(\"Weights & Bias hasil training:\", model_manual.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TensorFlow Functions (@tf.function)\n",
    "\n",
    "### Teori\n",
    "Python bersifat fleksibel tapi lambat. TensorFlow dapat mengubah fungsi Python menjadi **Graf TensorFlow** yang sangat cepat dan optimal untuk dijalankan di GPU/TPU menggunakan dekorator `@tf.function`.\n",
    "\n",
    "Saat fungsi dihiasi dengan `@tf.function`, TensorFlow akan melacak eksekusi fungsi tersebut (Tracing) dan membuat versi graf statisnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing fungsi... (hanya muncul saat kompilasi awal)\n",
      "Output 1: tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "Output 2: tf.Tensor(26.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def fungsi_cepat(x):\n",
    "    print(\"Tracing fungsi... (hanya muncul saat kompilasi awal)\")\n",
    "    return tf.square(x) + 1\n",
    "\n",
    "# Panggilan pertama: Tracing terjadi\n",
    "print(\"Output 1:\", fungsi_cepat(tf.constant(2.)))\n",
    "\n",
    "# Panggilan kedua: Menggunakan graf yang sudah dicache (tidak ada print Tracing)\n",
    "print(\"Output 2:\", fungsi_cepat(tf.constant(5.)))\n",
    "\n",
    "# Keras secara default menggunakan Graph Mode di belakang layar pada .fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kesimpulan Bab 12\n",
    "\n",
    "Bab ini memperlihatkan kekuatan TensorFlow di balik layar Keras:\n",
    "* **Tensor** adalah fondasi data.\n",
    "* **Custom Loss/Metric/Layer** memungkinkan adaptasi model untuk masalah spesifik.\n",
    "* **GradientTape** memberikan kendali penuh atas alur matematika pelatihan.\n",
    "* **@tf.function** digunakan untuk meningkatkan performa produksi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
